{"cells":[{"cell_type":"markdown","source":["### Inicjalizacja środowiska"],"metadata":{}},{"cell_type":"code","source":["import json\n\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext, SparkSession\nfrom pyspark.ml import Pipeline, Transformer\n\nfrom modules.features import (\n    MeanFeaturesTransformer,\n    MedianFeaturesTransformer,\n    NumberOfOccurrencesFeaturesTransformer\n)\n\nsc = SparkContext('local[*]', 'PipelineFlow')\nsess = SparkSession(sc)\nsqlContext = SQLContext(sc)\n    "],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["### Wczytywanie plików"],"metadata":{}},{"cell_type":"code","source":["def load_features(spark_ctx, files):\n    rdd = spark_ctx.wholeTextFiles(files)\n    rdd = rdd.map(lambda x: (x[0], x[1]))\n    df = rdd.toDF(['file', 'content'])\n    return df\n\ndef load_posts(spark_ctx, files):\n    rdd = spark_ctx.wholeTextFiles(files)\n    rdd = rdd.map(lambda x: (x[0], json.loads(x[1])))\n    df = rdd.toDF(['file', 'content'])\n    return df"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["### Przykład zastosowania TransformerProxy do automatyzacji ewaluacji"],"metadata":{}},{"cell_type":"markdown","source":["Eksploracja metod wykorzystuje dostarczany przez Sparka mechanizm `CrossValidator`a, który szuka optymalnych wartości w zadanej wcześniej przestrzeni parametrów pipeline'u.\n\nPonieważ `CrossValidator` może jedynie podmieniać wartości parametrów stage'y , nie zaś same stage, wykorzystujemy obiekty `TransformerProxy` do zasymulowania podmiany stage'y w trakcie cross-walidacji.\n\n`TransformerProxy` posiada pole `transformer` przeznaczone dla 'właściwego' transformera, który będziemy chcieli wypróbować. \n\n`CrossValidator` otrzyma przestrzeń parametrów, w której zamiast 'zwykłych' parametrów liczbowych będą się znajdować różne implementacje transformerów, przypisane do odpowiednich stage'y.\n\nTym spososbem będziemy w stanie modyfikować logikę działania pipeline'u bez tworzenia własnych nakładek a jedynie kreatywnie wykorzystując istniejące w Sparku mechanizmy."],"metadata":{}},{"cell_type":"markdown","source":["### Klasa TransformerProxy"],"metadata":{}},{"cell_type":"code","source":["class TransformerProxy(Transformer):\n\n    def __init__(self):\n        super(TransformerProxy, self).__init__()\n        self.transformer = Param(self, \"transformer\", \"\")\n\n    def set_transformer(self, transformer):\n        self._paramMap[self.transformer] = transformer\n        return self\n\n    def get_transformer(self):\n        return self.getOrDefault(self.transformer)\n\n    def _transform(self, dataset):\n        return self.get_transformer().transform(dataset)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Utworzenie instancji transformerów"],"metadata":{}},{"cell_type":"code","source":["from transformer.feature_filter import FeatureFilterTransformer \n\nfeatures = [\n        \"leaf\",\n        \"has-attribute-class\",\n    ]\n\nfeature_filter = FeatureFilterTransformer(keep=features)\nfeature_filter.setInputCol('content').setOutputCol('filtered_content')\n\nmean = MeanFeaturesTransformer(features=features)\nmean.setInputCol('filtered_content').setOutputCol('metric')\n\nmedian = MedianFeaturesTransformer(features=features)\nmedian.setInputCol('filtered_content').setOutputCol('metric')\n\ncount = NumberOfOccurrencesFeaturesTransformer(features=features)\ncount.setInputCol('filtered_content').setOutputCol('metric')\n    "],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["filter_stage_proxy = TransformerProxy()\nmetric_stage_proxy = TransformerProxy()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["#### Przygotowanie przestrzeni parametrów \n\nKażdy transformer w pipelinie stanowi osobny wymiar w przestrzeni parametrów.\nW naszym przypadku grid ma 2 wymiary o 'wielkosciach' odpowiednio 1 i 3"],"metadata":{}},{"cell_type":"code","source":["param_grid_builder = ParamGridBuilder()\n  param_grid_builder.addGrid(filter_stage_proxy.transformer, [feature_filter])\n  param_grid_builder.addGrid(metric_stage_proxy.transformer, [mean, median, count])\nparam_grid = param_grid_builder.build()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["### Przygotowanie modyfikowalnego pipeline'u\nW tej wersji, wszystkie istniejące wczesniej stage zastępujemy obiektami `TransformerProxy`"],"metadata":{}},{"cell_type":"code","source":["parameterized_pipeline = Pipeline(stages=[filter_stage_proxy, metric_stage_proxy])"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["evaluator = RegressionEvaluator(labelCol=\"metric\",\n                                predictionCol=\"evaluation\",\n                                metricName=\"rmse\")\n\n# CrossValidator will automatically find the best set of parameters\ncv = CrossValidator(estimator=parameterized_pipeline,\n                   estimatorParamMaps=parameter_grid,\n                   evaluator=evaluator,\n                   numFolds=1) # numFolds=1 zapewnia, że każdy zestaw metod zostanie przetestowany tylko raz"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["feature_file = 'external/data/featuresample.json'\nloaded_features = load_features(sc, feature_file)\n\ncv_result = cv.fit(loaded_features)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["### Wypisanie nazw transformerow wybranych przez CV"],"metadata":{}},{"cell_type":"code","source":["transformed_input_dataframe = cv_result.transform(example_dataframe)\ntransformed_input_dataframe.show()\n\n# print out the name of the best transformer\nprint(\"Selected transformers:\")\n  for stage in model.bestModel.stages:\n    best_transformer_param = stage.getParam(\"transformer\")\n    best_transformer = stage._paramMap[best_transformer_param]\n    print(type(best_transformer).__name__)\n"],"metadata":{},"outputs":[],"execution_count":19}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python","file_extension":".py"},"name":"PipelineCV","notebookId":3084768362551374},"nbformat":4,"nbformat_minor":0}
